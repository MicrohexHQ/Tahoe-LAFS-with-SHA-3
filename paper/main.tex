\documentclass[english,12pt,a4paper]{book}
\usepackage[T1]{fontenc} % In case we want special characters
\usepackage[utf8]{inputenc} % We are all writing in UTF-8

\usepackage[numbers]{natbib} % We need to tweak our referencing a bit.
\usepackage{appendix} % Fixes formatting of appendices
\usepackage[printonlyused]{acronym} % Package to handle the acronym list
\usepackage{graphicx} % We *may* use images
\graphicspath{{images/}} % and it is clean to put them in a separate dir
\usepackage{hyperref} % Internal and external links is nice
\hypersetup{pdfborder=0 0 0} % ..especially without red borders

% Packages and settings for code listings
\usepackage{listings}
\usepackage{caption}
\usepackage{upquote}
\usepackage{xcolor}
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}
\lstset{
language=Python,
keywordstyle=\bfseries\ttfamily\color[rgb]{0,0,1},
identifierstyle=\ttfamily,
commentstyle=\color[rgb]{0.133,0.545,0.133},
stringstyle=\ttfamily\color[rgb]{0.627,0.126,0.941},
showstringspaces=false,
basicstyle=\small,
numberstyle=\footnotesize,
numbers=left,
stepnumber=1,
numbersep=10pt,
tabsize=2,
breaklines=true,
prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
breakatwhitespace=false,
aboveskip={1.5\baselineskip},
columns=fixed,
upquote=true,
extendedchars=true,
frame=bottomline,
inputencoding=utf8
}

% Set equal margins on book style
% \usepackage{layout} % Use \layout to print out the margins (debug)
\usepackage{geometry}
\geometry{bindingoffset=1cm}

% Restyle chapter headers
\usepackage{fix-cm}
\makeatletter
\renewcommand{\@makechapterhead}[1]{%
  \vspace*{50\p@}%
  {\parindent \z@ \raggedright \normalfont
    \vspace{15pt}%
    \ifnum \c@secnumdepth >\m@ne
        %\hfill\huge\scshape \@chapapp\space
        \hfill\fontsize{60}{90}\selectfont \thechapter % Chapter number
        \par\nobreak
        \vskip 20\p@
    \fi
    \interlinepenalty\@M
    \hfill \Huge \scshape #1\par % Chapter title
    \vspace{5pt}
    \hrule
    \nobreak
    \vskip 40\p@
  }}
\makeatother

\author{Eirik Haver \and PÃ¥l Ruud}
\title{Project assignment - Tahoe-LAFS with SHA-3 candidates}
\date{\today}

\begin{document}

\include{title}
\pagestyle{empty}

\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
\pagestyle{plain}
\pagenumbering{Roman}
\setcounter{page}{1}

\chapter*{Preface}
\addcontentsline{toc}{chapter}{Preface}

\tableofcontents

\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{\listfigurename}
\listoffigures

\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{\listtablename}
\listoftables

\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{\lstlistlistingname}
\lstlistoflistings
\cleardoublepage

\chapter*{Acronyms}
\addcontentsline{toc}{chapter}{Acronyms}

\begin{acronym}
\acro{AES}{Advanced Encryption Standard}
\acro{API}{Application programming interface}
\acro{BMW}{Blue Midnight Wish}
\acro{CEB}{Capability Extension Block}
\acro{CPU}{Central Processing Unit}
\acro{Distutils}{Python Distribution Utilities}
\acro{FEC}{Forward Error Correction}
\acro{GCC}{GNU Compiler Collection}
\acro{KAT}{Known Answer Test}
\acro{LAFS}{Least-Authority Filesystem}
\acro{NIST}{National Institute of Standards and Technology}
\acro{RAM}{Random Access Memory}
\acro{RAID}{Redundant Array of Independent Disks}
\acro{SHA}{Secure Hash Algorithm}
\acro{SSE2}{Streaming SIMD Extensions 2}
\acro{SSSE3}{Supplemental Streaming SIMD Extensions 3}
\acro{SUPERCOP}{System for Unified Performance Evaluation Related to
Cryptographic Operations and Primitives}
\acro{SVN}{Subversion}
\acro{UEB}{URI Extension Block}
\acro{URI}{Uniform Resource Identifier}
\end{acronym}

%**************************************%
\chapter{Introduction}
%**************************************%
\pagenumbering{arabic}
\setcounter{page}{1}

Thorough problem description. \\
Stepwise, what will we actually do?

Scope and objectives

\section{Method}

All work associated with the project has been carried out by the two authors in
cooperation. Code are written using the VIM editor on Ubuntu Linux
driven machines, and version-controlled using the distributed revision control
system Git. All material produced, including this paper, are publicly available
on GitHub\footnote{\url{http://github.com/ruudud/Tahoe-LAFS-with-SHA-3}}.

The \ac{SHA}-3 candidates are tested on the Tahoe-\ac{LAFS} using uploading and
downloading of files on four desktop computers. Various file sizes are used to
simulate different use cases, and to broaden the perspective as to how the
different candidates perform and behaves when implemented in a secure,
distributed file system.

\section{Outline}

The work is presented as per the following chapters:

\paragraph{Chapter 2} provides background knowledge of the technologies and
software used.

\paragraph{Chapter 3} outlines the procedure taken to be able to do the
measurements.

\paragraph{Chapter 4} presents the actual results, in the form of graphs and
tables, in addition to some easily seen conclusions.

\paragraph{Chapter 5} discusses the results and our technical procedure to the
problem presented in this assignment.

\paragraph{Chapter 6} concludes the results and the work done, and proposes
future work.


%**************************************%
\chapter{Background technologies}
%**************************************%

\section{Cryptographic Hash Functions}

A cryptographic hash function is a deterministic mathematical procedure which
takes an arbitrary block of data and outputs a fixed-size bit string. The output
is referred to as the hash value, message digest or simply digest.
Another property of a cryptographic hash function is that the smallest change in
the input data (e.g. one bit) should completely change the output of the hash
function. In other words it should be infeasible to find the reverse of a
cryptographic hash function \cite[p. 335]{stallings}. It should also be infeasible to
find two blocks of data which produce the same hash value (a \emph{collision}).

\subsection{NIST SHA-3 Competition}
The \ac{SHA} version 3 is a coming standard set to supersede the current
standards that the \ac{SHA}-1 and the \ac{SHA}-2 family has become. The hash
function that will be known as \ac{SHA}-3 will be decided by the \ac{NIST} and
chosen between the submitted contestants to the \ac{NIST} hash competition.
At the time of writing, the current status of the competition is officially
called Round 2, with 14 of 64 candidates having ``survived'' Round 1
\cite{s_fedreg}.

\subsubsection{\ac{NIST} evaluation criteria for \ac{SHA}-3}

\label{sec:lengthextension}
\paragraph{Security.} The most important criterion for the SHA-3
candidates\cite{s_nistround2} is security. \citet{s_fedreg} lays out the full
description of security criteria, however the most noteworthy criterion
in regards to Tahoe-\ac{LAFS} is that \ac{SHA}-3 candidates are required to have
resistance against length-extension attacks. Both \ac{SHA}-1 and the \ac{SHA}-2
family are vulnerable to this kind of attack, and thus requires
Tahoe to run the algorithm twice, as described by \citet{schneier}.

\paragraph{Cost and Performance.} Cost and Performance are considered to be the
2nd most important criterion. The absolute minimum for performance is that the
SHA-3 candidate should be faster than the functions in the \ac{SHA}-2 family.
Cost is a measure of how much memory an implementation requires in software,
both the implementation itself and the use of \ac{RAM} during runtime. Another
measure of cost is how many logic gates it takes to implement the function in
hardware.

\paragraph{Algorithm and implementation characteristics.} By this 3rd criterion,
\ac{NIST} emphasizes that algorithms with greater flexibility will be given
preference over other algorithms \cite{s_nistround2}. By flexible, they imply
the possibility of the function to run efficiently on a variety of platforms,
and to use parallelism and instruction set extensions. Another key point of a
flexible hash function is that it should have a simple and elegant design to
encourage understanding, analysis and design confidence.

\subsubsection{\ac{NIST} \ac{SHA}-3 \ac{API}} \ac{NIST} required that every
submission should conform to a specified \ac{API}\cite{s_fedreg}. The \ac{API}
specification \cite{s_nistapi} states in shortness that it requires every
candidate to implement four functions:

\begin{verbatim}
HashReturn Init(hashState *state, int hashbitlen);
HashReturn Update(hashState *state, const BitSequence *data,
    DataLength databitlen);
HashReturn Final(hashState *state, BitSequence *hashval);
HashReturn Hash(int hashbitlen, const BitSequence *data,
    DataLength databitlen, BitSequence *hashval);
\end{verbatim}

The {\verb Init() } function basically sets up the internal state of the function, to
make it ready to start processing real data. The {\verb Update() } function is used to
provide the actual data to the hash function. The {\verb Final() } function should be
called when all necessary data has been given through {\verb Update() }, it will then
finish the hash function and provide the digest. The {\verb Hash() } function
can be described as a wrapper for doing a call to the three other functions.

{\verb HashReturn } is an \emph{enum} representing that an operation either succeeded or
went wrong. The {\verb BitSequence } is a representation of an array of byte fields and
{\verb DataLength } represents the size in bits of the data provided.

\subsubsection{The second round candidates}
The names of the second round candidates for the \ac{SHA}-3 \ac{NIST}
competition along with their principal submitters are listed in Table
\ref{tbl:sha3:candidates} \cite{s_nistround2}.

\input{tables/sha3_authors}

\subsection{\ac{SUPERCOP}}
\ac{SUPERCOP} is a toolkit developed by VAMPIRE lab for measuring performance
of cryptographic software \cite{s_supercop}. In relation to hash functions,
\ac{SUPERCOP} measures the following:

\begin{itemize}
    \item Time to hash a very short packet of data.
    \item Time to hash a typical-size Internet packet.
    \item Time to hash a long message.
    \item Length of the hash output.
\end{itemize}

The Round 2 \ac{SHA}-3 candidates are all included in the toolkit, with a number
of different optimizations for each candidate. Optimizations range from
32-/64-bit specific implementations, the use of extended instruction sets such
as \ac{SSE2} and \ac{SSSE3}, optimizations for different number of cores and
others. The toolkit will also try different compiler optimizations to get the
best results possible for each function.

The benchmarking results for the \ac{SUPERCOP} toolkit of the \ac{SHA}-3
candidates and \ac{SHA}-2 functions on a number of different plattforms and
architectures are available at the webpage of eBACS
\footnote{\url{http://bench.cr.yp.to/results-sha3.html}}.
%FIXME: Reference appendix if tahoe04 results end up there.

\subsubsection{\ac{SUPERCOP} \ac{API}}
\ac{SUPERCOP} specifies an \ac{API} which all submitted implementations must
conform to \cite{s_supercopapi}. This \ac{API} specifies the naming and
organization of files, and that a submission must include a function
{\verb crypto_hash() } which is similar to the function {\verb Hash() } in the
\ac{NIST} \ac{SHA}-3 \ac{API}. The only difference being the naming of
data types and that the {\verb crypto_hash() } function does not need an input
of how long the output of the hash function should be. Instead double or
different submissions are used for different output lengths.

\begin{verbatim}
int crypto_hash(unsigned char *out, const unsigned char *in,
    unsigned long long inlen)
\end{verbatim}

\section{Tahoe-LAFS}
%What is it, how/where are hash functions used, Python, pycryptopp
%comparison with RAID-6, mutable/immutable?

The Tahoe \ac{LAFS} is a system for secure,
distributed data storage. Files are encrypted client side, then
split up, before each part is sent to other nodes in the grid, as depicted in
Figure \ref{fig:tahoeinsertion}. The integrity and confidentiality of the files
are guaranteed by the algorithms used on the client, and is independent of the
storage servers, which may be operated by untrusted people. This is defined as
\emph{provider-independent security} \cite{t_tahoe}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\columnwidth]{Tahoe-newfile.pdf}
    \caption{Tahoe-LAFS: Insertion of new file}
    \label{fig:tahoeinsertion}
\end{figure}

Tahoe was originally developed with funding from the former commercial web
backup service provider Allmydata, but is now a stand-alone Open
Source\footnote{GNU General Public License (GPL) version 2} project
\cite{t_ars}.  It is written in the Python programming language with the Twisted
framework, and can run on Windows, Mac OSX, Linux, Solaris and more.

\subsection{Architecture}

Tahoe has a three layer architecture: the key-value store, the filesystem, and
the application \cite{t_tahoe}.

The \textbf{key-value store}, or the ``capability-data bytes'' store, is the
lowest layer and is implemented by a grid of Tahoe-LAFS storage servers. Data is
kept on the storage servers in the form of ``shares'', which are encrypted and
encoded parts of files. Capabilities are short ASCII strings, containing
information on where to \emph{find} a file, and how to \emph{verify} it.
Nodes in the grid learn about each other through an ``introducer'', which
roughly relates to a tracker in the BitTorrent\footnote{See
\url{http://www.bittorrent.org/beps/bep\_0003.html}} protocol.

The \textbf{filesystem} layer is responsible for mapping human-meaningful
pathnames to pieces of data. Each directory contains a table of capabilities
for its children, i.e. subdirectories or files. Two forms of capabilities is
available for each file, read-only and read-write, and these can be shared to
provide shared/published directory structures with friends.

Since it is not practical for users to remember strings containing random
characters, the \textbf{application} layer is used for providing a user-friendly
interface to the directories and files.

\paragraph{File types.}

There are two kinds of files in the Tahoe-\ac{LAFS} -- \textbf{immutable} and
\textbf{mutable} files. An immutable file is created exactly once, i.e. it
cannot be modified, and can be read repeatedly. Mutable files can be modified,
and everyone who has access to the signing key can make new versions of
the mutable file.
%More text here?

\paragraph{Erasure coding.}

When a client puts a file on the grid, it first encrypts the file, before
breaking the file into small segments. The segments are then \emph{erasure
coded}.  The use of the Solomon-Reed erasure coding scheme, enables Tahoe to
recover a file using only a predefined subset of the parts distributed to the
storage servers, i.e. the other nodes in the grid. Erasure coding is a type of
\ac{FEC} code, which extends a message with $C$ characters into a longer message
with $N$ symbols \cite{t_reed-solomon}.  The original $C$ characters can then be
recovered from a subset of the $N$ symbols.

The properties of erasure coding can be thought of as those of replication in
\acsu{RAID} systems. \citet*{t_erasure} compare erasure coding and plain
replication, and conclude that ``\emph{...  erasure codes have mean time to
failures many orders of magnitude higher than replicated systems with similar
storage and bandwidth requirements.}''

\subsection{Use of secure hashes in Tahoe-LAFS}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\columnwidth]{Tahoe-hashes.pdf}
    \caption{Tahoe-LAFS: Example of hashing operations.}
    \label{fig:tahoehashing}
    \emph{Figure based on
     \href{http://tahoe-lafs.org/source/tahoe/trunk/docs/specifications/CHK-hashes.svg}
     {CHK-hashes.svg from Tahoe-LAFS documentation}}
\end{figure}

As seen in Figure \ref{fig:tahoehashing}, the usage of secure hashing is
extensive in Tahoe, and has to be considered as a key part of the functionality,
and thus affecting the performance.

\paragraph{Hash Trees.}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\columnwidth]{Tahoe-MerkleTree.pdf}
    \caption{Example of a Merkle tree.}
    \label{fig:tahoemerkletree}
\end{figure}

A hash tree, also known as a \emph{Merkle tree}, is a type of data structure
which can be described as a tree with nodes that can verify all information
below in the hierarchy, as depicted in Figure \ref{fig:tahoemerkletree}. This
enables Tahoe to verify small segments of a file at the time, and this can be
used for instance to start playing a movie file while it is still being
downloaded.

These secure hashes of the shares of a file, are contained within a small
data structure named the \emph{\ac{CEB}}.

\paragraph{Capabilities.}

A \textbf{capability} (or an URI) contains the encryption key, and a hash of the
\emph{\ac{UEB}}. The \ac{UEB} for each file is a data structure containing the
hash of the \ac{CEB}, the size of the file, any encoding parameters necessary to
perform the erasure decoding, and a hash of the plaintext and the encrypted
text. This is illustrated in Figure \ref{fig:tahoeueb}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\columnwidth]{Tahoe-UEB.pdf}
    \caption{The composition of an \ac{UEB}.}
    \label{fig:tahoeueb}
\end{figure}

\paragraph{Storage Index.}

A hash of the encryption key is used to form the "storage index", which is
used for both server selection and to index shares within each storage node.
% More here?

\section{Python and Cython}

Python\footnote{\url{http://www.python.org/}} is a high-level general-purpose
programming language. Python is also an interpreted language, which means that
Python programs are compiled at runtime. There exists multiple implementations
of Python, however the most common, CPython, is implemented in C. The fact that
Python is a high-level language usually means that there are performance
penalties in contrast to lower level languages, such as C. To remedy this
problem it is possible to write extensions to the language by using the official
C-API. This approach has been used by several cryptographic libraries for
Python, such as pycryptopp\footnote{\url{http://tahoe-lafs.org/trac/pycryptopp}}
and the official hashlib\footnote{\url{http://code.krypto.org/python/hashlib/}}.

Tahoe-\ac{LAFS} is written in Python, but the SHA-3 candidate implementations found
in both the official NIST submissions and SUPERCOP are either in C or in
assembly. Therefore it is necessary to either implement the functions in Python
or make extensions to Python through the C-API, where extensions should give
the best performance.

\subsection{Cython}
Cython\footnote{\url{http://www.cython.org/}} is a language for writing Python
extensions in a language that closely resembles the Python language itself.
Basically what Cython does, is to parse Cython files and generate C source files
that utilises the Python C-API. Afterwards the generated source files can be
compiled as if they were written directly in C.

Direct calling of external C functions and methods are also supported, thus
making Cython an attractive way of wrapping external libraries written in C to
enable access from Python code.

Since the generation of C source files is an automated procedure, a small
performance trade-off is to be expected, due to the extra layer of abstraction.
The gain on the other hand, is significant in comparison to implementing
functions directly in Python.

%**************************************%
\chapter{Technical Procedure}
%**************************************%

%A bit more technical description of how we tested the candidates in Tahoe-LAFS
% - Limitations/assumptions
% - Optimized candidates.
% - Error sources.
% The points above should be taken into consideration on each section in this
% chapter.

In this chapter we will outline the procedure followed to complete our work.
Although not carried out sequentially, the problem was split up to the
following parts:

\begin{enumerate}
  \item Choose the best suiting implementations of the SHA-3 candidates.
  \item Write Python bindings, with unit tests for verification, to be able to
    use the functions from Python.
  \item Modify the Tahoe-LAFS code to utilize the SHA-3 functions.
  \item Create a method of distributing new code fast and easy to the test grid.
  \item Set up the test environment and choose test vectors.
\end{enumerate}

\section{Choosing implementations of the SHA-3 Candidates}

While the official \ac{NIST} \ac{SHA}-3 second round submissions contain both
a reference version and optimized versions of the candidates, it does not
appear to be updated since the submission deadline on September 15, 2009. They
also do not contain any benchmarking utility which could be used to decide on
the best implementation for a particular platform or architecture. \ac{SUPERCOP}
on the other hand, provides both, in combination with results stating which
compiler arguments that gives the best performance. On the downside, the
\ac{SUPERCOP} \ac{API} only specifies the {\verb crypto_hash() } function and
not an {\verb update() } function which Tahoe-\ac{LAFS} is dependent on using.

Since Tahoe-\ac{LAFS} is using \ac{SHA}-256 internally, we only test \ac{SHA}-3
functions with 256-bit output in our implementation.

\subsection{Criteria for implementation selection}

We chose the fastest implementation of each candidate that conforms to the
following criteria:
\paragraph{Criterion 1} The implementation must have an \ac{API} defined in C.
\paragraph{Criterion 2} The implementation must include a working {\verb update() } function.
\paragraph{Criterion 3} The implementation must not use assembly that can not be made
    position independent by \ac{GCC}.%FIXME: State the reason for this somewhere?
\paragraph{Criterion 4} The implementation should conform to the \acp{KAT} specified in the
    \ac{NIST} submission package, or later updates by the author.

\vspace{12pt}
Based on these criteria, we choose the fastest possible implementation based
on our benchmark in \ac{SUPERCOP}. The relative speed of each implementation, in
relation to other implementation for the same and other candidates are
available at source.
% FIXME: Link to appendix with tahoe04 SUPERCOP results.

\subsection{Chosen implementations}

\input{tables/sha3_implementations}

The chosen implementations are shown in Table \ref{tbl:sha3:implementations}.
Their compiler flags used, which are extracted from the \ac{SUPERCOP} results,
can be seen in Table \ref{tbl:sha3:compilerflags}. Compiler flags are described
in the GCC manual\footnote{GCC Manual \url{http://gcc.gnu.org/onlinedocs/}}.
Compiler flags used for every implementation which might affect performance are:

\begin{itemize}
    \item -fomit-frame-pointer
    \item -mssse3
    \item -pthread
    \item -fPIC
\end{itemize}

It should be noted that \emph{32} in blake32 means the function works on 32-bit
words, and output a 32-byte digest (256 bit). Similarly, \emph{512} in keccakc512 
does not mean 512-bit output, but 512 bits in the internal capacity.

The relative speeds of the implementations chosen compared to
the best version in \ac{SUPERCOP}, and relative speed of the benchmark compared
to other candidates, can bee seen in Table \ref{tbl:sha3:speedrelative}.
Worth mentioning is that the fastest SHA-256 implementation in \ac{SUPERCOP} is
cryptopp\footnote{\url{http://www.cryptopp.com/}}, which is the one used by
Tahoe-\ac{LAFS}. For the most part we have found working versions of all
candidates in \ac{SUPERCOP}, however there are some exceptions.

\input{tables/sha3_flags}

\input{tables/sha3_relativespeed}

\paragraph{JH} seems to be broken in every implementation with regard to
Criterion 2. For both the optimized versions found in \ac{SUPERCOP} and the
reference implementations in the \ac{NIST} submission package,
{\verb Hash("foofoo") } will not yield the same result as two consecutive calls
to {\verb Update("foo") }.  However the implementation in sphlib does fulfill
this requirement. We have contacted the author, Thomas Pornin, which confirms
this problem with the official JH candidate and that the author has been made
aware of the problem but has not released any updated version yet
\cite{s_pornin}.

\paragraph{Cubehash} sadly does not have a version in \ac{SUPERCOP} with a 256-bit
output, which is why we have only included a version from sphlib.

\paragraph{Simd vect128 implementation} does not by default conform to Criterion
4, because of a bug in the implementation. This has been confirmed by the author
who also supplied us with a patch to correct the bug (GaÃ«tan Leurent, personal
communication, November 10, 2010).

\paragraph{Blake32 \ac{SSSE3}} implementation also fail to completely fulfill
Criterion 4, however it does validate all test vectors that have a length
in bits which is a multiple of 8. Since our Python wrappers only allow (and
only need) to provide data in full bytes, we decided to keep this
implementation.

\paragraph{Shavite3} seems to have received an update\footnote{See
\url{http://www.cs.technion.ac.il/~orrd/SHAvite-3/}}. We have observed that
implementations of Shavite3 in \ac{SUPERCOP}-20101014 or later seems to fail to
verify the \ac{KAT}s, while the version we have used does. We believe this is
only because newer \ac{KAT}s will have to be generated, but since the author
has not done so, we chose to use an older version of the algorithm.

\section{Python bindings}

Since Tahoe-\ac{LAFS} is written in Python, we needed some way of interacting
with the C implementations of the NIST candidates. We did this by the use of
Cython, and built a Python object-oriented library which we named SHA3lib.
SHA3lib supports all of the 14 second round \ac{SHA}-3 candidates, but only in
their 256-bit form.

\subsection{SHA3lib}
SHA3lib is built to mimic the functionality of
hashlib\footnote{\url{http://docs.python.org/library/hashlib.html}}, the
default Python library for MD5, \ac{SHA}-1 and the \ac{SHA}-2 family. This
made us create class names for each candidate on the form
\emph{candidate name+256}. In addition, the classes included the following
functions:

\begin{itemize}
    \item Constructor with an optional data element that does the same as
    {\verb update() }
    \item {\verb update() } takes data that should be considered in hashing
    \item {\verb digest() } that produce a raw byte-digest from submitted data
    \item {\verb hexdigest() } that produce a hex representation of the digest
    \item {\verb copy() } that copies the internal state of the function and
        produces a copy of the object.
\end{itemize}

\subsubsection{Design}
Our original goal was to make SHA3lib include functionality to support all
output lengths, and not only 256-bit. This was based on our observation that
the official \ac{NIST} submission packages include ``all-in-one''
implementations that support this. Later we observed that this is not the case
for all implementations in \ac{SUPERCOP}. Together with the fact that
Tahoe-\ac{LAFS} uses 256-bit output we in the end only included support for
256-bit output in SHA3lib. The design we have used is shown in Figure
\ref{fig:python:inheritance}, and does follow the initial idea that SHA3lib
should support multiple output lengths.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.6\columnwidth]{python-inheritance.pdf}
    \caption{Design of SHA3lib using echo as an example}
    \label{fig:python:inheritance}
\end{figure}

Basically the class \textbf{echo} resides in Cython and in C, and is responsible
for bringing the C functionality of the C implementation to Python. By compiling
\textbf{echo} it will be made available for use in Python.  The class
\textbf{echo256} is a simple Python class which inherits from \textbf{echo}. The
only action this class actually takes is to set the output size to 256-bit. If
the underlying C-functions would have supported multiple output sizes the same
could have been done to incorporate those.

\subsubsection{Cython}
We employ Cython to generate bindings for the C implementation and the
different candidates, as well as to create the base Python classes. To access
functions in C we need to generate a Cython header file, which pretty much does
the same as a C header file; it tells which functions and data types are
available. How we accomplish this for an implementation that satisfies the
\ac{NIST} \ac{API} is shown in Listing \ref{lst:cython_header}.

\lstinputlisting[label=lst:cython_header, caption=Cython header\, echo\_hash\_h.pxd]
{listings/echo_hash_h.pxd}

We then create a wrapper-class that mimics hashlib, this is shown in Listing
\ref{lst:cython_impl}. Functions declared with def er Python functions,
{\verb cdef } are Cython only while {\verb cpdef } are functions that can be
accessed from both. While this is just the implementation for the echo
candidate, the almost exact same pattern is used for all of the other
candidates.

\lstinputlisting[label=lst:cython_impl, caption=Cython class\, echo\_hash.pyx]
{listings/echo_hash.pyx}

\subsubsection{\ac{Distutils}}
We use \ac{Distutils}\footnote{\url{http://docs.python.org/distutils/}} to
build and install our code. The alternative to doing this would be to manually
transform Cython files to C-files, build the shared library from this and other
relevant C-files and then install by copying into the correct system directory
where Python libraries should be stored. \ac{Distutils} also support expansion
through self defined commands, something we have utilised to do Unit Testing.
Options and configuration for \ac{Distutils} is done through a file
{\verb setup.py}. Relevant configuration for compiling the echo extension, and
installing SHA3lib can bee seen in Listing \ref{lst:setup_py}.

\lstinputlisting[label=lst:setup_py, caption=Compiling echo from \ac{Distutils}]
{listings/setup.py}

\subsection{Unit tests}
We Unit Test each new candidate implementation that is included SHA3lib, both
to verify our own work and to verify that the implementation from \ac{SUPERCOP}
actually are correct. 

\paragraph{Known-Answer Tests} are used to check that the implementation conform
to the specifications of the algorithm author. The \ac{KAT}s include
bytestrings, their length and their expected message digest. The length of the
inputs range from 0 bits to 34304 bits, and also include a message that should
be repeated for about 17 million times, to verify that the implementation can handle
large inputs.

\paragraph{Basic Hash Tests} is what we have named the set of tests which test
the core basics of what a hash function implementation will have to be able to
do to be usable. This include that Init(), Update() and Final() works as
expected, and that the output is of correct size. This include that every
function should produce the same digest for the inputs Update("foofoo") and two
consecutive calls to Update("foo").

\paragraph{Copy Hash Tests} does not test any of the functionality used by
Tahoe-\ac{LAFS}, but the copy()-function is a part of Hashlib, and we have
included it in SHA3lib to conform to this. The idea is that if we have two
bytestring that share a common prefix, we can input this prefix to Update(),
then copy the state. The tests check if this is possible, and that altering the
copied state does not affect the original.


\section{Modifications to the Tahoe-\ac{LAFS} Code}
\label{sec:modtahoe}

The code of Tahoe-LAFS conforms to the style guide of Python, known as PEP 8.
This, along with the code being highly modular and consistent to its
architecture, emphasizes code readability.
With some experience using Python, it is not difficult to learn the Tahoe code
enough to understand what is happening when a file is uploaded or downloaded
with the system.

All hashing operations requested by the Tahoe system is routed through a
couple of classes and functions, and the connection to the underlying hash
function library is made on only one line. This is displayed in Listing
\ref{lst:hashutil}.

\lstinputlisting[label=lst:hashutil, caption=Extract from hashutil.py of Tahoe-LAFS source.]
{listings/hashutil.py}

As stated in Section \ref{sec:lengthextension}, none of the SHA-3 candidates is
vulnerable to the length-extension attack. Since we are interested in finding
out how Tahoe-\ac{LAFS} performs when utilizing the SHA-3 functions, we can
remove the lines that fixes the length-extension problems manually. In addition,
to try out one of the new implementations, we change line one in Listing
\ref{lst:hashutil}, and an example of this can be seen in Listing
\ref{lst:hashutilmod}.

\lstinputlisting[label=lst:hashutilmod, caption=Parts of hashutil.py of Tahoe-LAFS source after modification.]
{listings/hashutil_mod.py}

Some notes has to be made regarding the first line in Listing
\ref{lst:hashutilmod}. For every candidate we test, the whole setup and grid is
started from ground up, since changing the hash function this way cause a
backwards compatibility break, making it impossible to download files put to the
grid while using another hash function.

For the same reasons, some of the built-in unit tests of Tahoe-LAFS fail when
changing this line, because they contain test fixtures made with the included
SHA-256.  An implication of this is that uploading of mutable files renders
impossible, since the internal verification fails. For this reason, \emph{only
immutable files} are tested and measured in this paper. Implications of this are
discussed further in Chapter \ref{ch:discussion}.

\section{Automatic testing and distribution}
We fully automate the testing procedure. This is achieved by the use of
software revision control systems, which distributes both the source code of
Tahoe-LAFS, SHA3lib and shell-scripts for installation and configuration of
both. Configuration is mainly done by the use of regular expressions.

The outline of this procedure is:

\vspace{12pt}
\noindent For every \ac{SHA}-3 candidate:
        \begin{enumerate}
            \item Install SHA3lib on all nodes
            \item Replace used hash algorithm in Tahoe-LAFS with current
            candidate
            \item Install Tahoe-LAFS
            \item Create and start one Tahoe-LAFS introducer
            \item Create and start Tahoe-LAFS storage nodes on 3 nodes
            \item Create a Tahoe-LAFS client on a previously unnused node
            \item Do testing
            \item Clean up
        \end{enumerate}

\paragraph{Distribution of source code for Tahoe-LAFS and SHA3lib} is done by
\ac{SVN} and GIT respectivly. The change of hash algorithm in Tahoe-LAFS is
however done with the use of a regular expression, because of both the
simplicity of the change, and to not clutter the revision control system. Both
Tahoe-LAFS and SHA3lib uses \ac{Distutils}, which includes options to install
them globally on a system.

\section{Configuration of Test Environment}

Four machines was used as a testing grid, each containing an Intel(R) Core(TM)2
Duo E8300 \ac{CPU} and 4GB of \ac{RAM}. The 32-bit version of Ubuntu Linux
Server Edition 10.04 was the operating system of choice. The installed versions
of other relevant software can be seen in Table \ref{tbl:installedsw}.

\input{tables/installed_software}

Tahoe-\ac{LAFS} was configured to have three storage nodes available --
\emph{shares available} -- and that only two of these had to be accessible to be
able to restore files from the grid -- \emph{shares needed}. A setting called
\emph{shares happy} was set to three storage nodes. This makes Tahoe ensure that
all storage nodes are available, so that the test environment behaves the same
for all the different tests.

The performance measurements were only performed on the Tahoe client, and not on
the storage servers. We motivated this by looking at the system performance
graphs of the storage nodes during upload and retrieval, where neither the
\ac{CPU}, network, disk or memory usage raise towards maximum threshold. The
\ac{CPU} usage during testing on one of the storage nodes is depicted in Figure
\ref{fig:munin:storagenode}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\columnwidth]{munin-tahoe05-cpuday.png}
    \caption{Graph of CPU usage during testing on a Tahoe storage node.}
    \label{fig:munin:storagenode}
\end{figure}

The tests was carried out as follows, for each of the test vectors:

\begin{itemize}
  \item Upload all files in the same category (as defined shortly) one by one.
  \item Download all files in the same manner.
\end{itemize}

During these operations, we counted the number of hashing operations performed,
and timed total time spent hashing, i.e. the total time it took for the function
calls to the underlying hashing operations to complete.

\subsection{Test Vectors}

A variety of different files was uploaded and subsequently downloaded using the
configured Tahoe grid. The numbers of the randomly generated different files
tested are shown in Table \ref{tbl:test_vectors}.

\input{tables/test_vectors}

The distribution of file sizes is based on the need to test different use cases.
Although it is probably unusual to upload one byte files, this enables us to see
what happens when network delay is brought to a minimum. At the other extreme,
the one gigabyte file will show another perspective of resource utilization.

% FIXME: Maybe add some more reasoning here.

%**************************************%
\chapter{Measurements and Results}
%**************************************%

% FIXME: Decide whether Munin should be included?

In this chapter, we will focus on the concrete results derived from our testing.
The method of testing is described, along with the test scope.

Further on, we exhibit the results from the \ac{SUPERCOP} benchmark, before
presenting the graphs of how much time the hashing operations take when
downloading and uploading a number of different test vectors, and show these
data in relation to other measurements, such as total operation time.

\section{Test scope}

As stated in Section \ref{sec:modtahoe}, only immutable files are tested. The
mutable files are not tested because of our way of integrating the SHA-3
candidates within the Tahoe-LAFS code.

To measure the performance impact of the different implementations, we time the
hash function calls from Tahoe, in addition to timing the total operation time,
e.g. the total time it takes for a 1GB file to be uploaded to grid.

\section{Measuring Performance}

Listing \ref{lst:hashutil_time} demonstrates the use of the {\verb time } module
in Python. On every call to {\verb update() } or {\verb digest() }, a variable
is increased with the time it took to run the underlying hash library
functionality. Similarly, Listing \ref{lst:testrunner} shows the use of the
{\verb date } command to calculate the number of seconds it takes it takes for
Tahoe to put a file to the grid.

\lstinputlisting[label=lst:hashutil_time, caption=Timing in Python (extraction from hashutil.py)]
{listings/hashutil_timing.py}

\lstinputlisting[language=sh, label=lst:testrunner, caption=Timing in Bash from test runner]
{listings/test_runner.sh}

\section{\ac{SUPERCOP} benchmarks}
% TODO: more introduction text here?

The results of the \ac{SHA}-3 256-bit functions and \ac{SHA}-256 benchmarking in
\ac{SUPERCOP} can be seen in tables \ref{tbl:supercop:long},
\ref{tbl:supercop:4096}, \ref{tbl:supercop:1536}, \ref{tbl:supercop:576},
\ref{tbl:supercop:64} and \ref{tbl:supercop:8}. The lower the numbers, the
faster and better the algorithms performed in the test.

\input{tables/supercop_long_msgs}
\input{tables/supercop_4096}
\input{tables/supercop_1536}
\input{tables/supercop_576}
\input{tables/supercop_64}
\input{tables/supercop_8}

\section{Measurements of Tahoe operations}
%\vskip -1.5em % This is to fit in two graphs on one page including heading

% How much time is spent on hashing versus total time of
%   uploading/downloading

The sum of the times it took for the underlying hash library to calculate the
hash operations are exhibited in Figures \ref{fig:graph:10001b},
\ref{fig:graph:1001kb}, \ref{fig:graph:501mb}, \ref{fig:graph:5100mb} and
\ref{fig:graph:11gb}. We call this \emph{time spent hashing}.

The numbers for uploading and downloading of one 1GB file are summarized in
Tables \ref{tbl:hashingtimes:put1gb} and \ref{tbl:hashingtimes:get1gb}.

\input{tables/hashingtimes}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\columnwidth]{graphs/TimespenthashingPUTof10001Bfiles.pdf}
    \includegraphics[width=0.9\columnwidth]{graphs/TimespenthashingGETof10001Bfiles.pdf}
    \caption{Figures for hash operations of 1000 1B files.}
    \label{fig:graph:10001b}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\columnwidth]{graphs/TimespenthashingPUTof1001KBfiles.pdf}
    \includegraphics[width=0.9\columnwidth]{graphs/TimespenthashingGETof1001KBfiles.pdf}
    \caption{Figures for hash operations of 100 1KB files.}
    \label{fig:graph:1001kb}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\columnwidth]{graphs/TimespenthashingPUTof501MBfiles.pdf}
    \includegraphics[width=0.9\columnwidth]{graphs/TimespenthashingGETof501MBfiles.pdf}
    \caption{Figures for hash operations of 50 1MB files.}
    \label{fig:graph:501mb}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\columnwidth]{graphs/TimespenthashingPUTof5100MBfiles.pdf}
    \includegraphics[width=0.9\columnwidth]{graphs/TimespenthashingGETof5100MBfiles.pdf}
    \caption{Figures for hash operations of five 100MB files.}
    \label{fig:graph:5100mb}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\columnwidth]{graphs/TimespenthashingPUTof11GBfile.pdf}
    \includegraphics[width=0.9\columnwidth]{graphs/TimespenthashingGETof11GBfile.pdf}
    \caption{Figures for hash operations of one 1GB file.}
    \label{fig:graph:11gb}
\end{figure}

%**************************************%
\chapter{Discussion}
%**************************************%
\label{ch:discussion}

\section{\ac{SUPERCOP} results}
% Time gain of removing ``double'' SHA-256. Double only in digest().

We see in Tables \ref{tbl:supercop:long}, \ref{tbl:supercop:4096},
\ref{tbl:supercop:1536}, \ref{tbl:supercop:576}, \ref{tbl:supercop:64} and
\ref{tbl:supercop:8} that in general BLAKE, \ac{BMW}, Luffa, Shabal and Simd
outperform \ac{SHA}-256. However, given that Tahoe-LAFS uses double
\ac{SHA}-256, this means that it will also have to hash another 32 bytes for
every message it hashes. Since \ac{SUPERCOP} does not have benchmark for 32
byte messages, we will have to estimate the amount of cycles required for this.
If we assume a worst case scenario of hashing 32 bytes, where the cycles/byte
count is exactly the same as for 8 bit median we get:

$$\frac{median * size + 179.62*32}{size} = SHA256d estimate$$

\input{tables/supercop_sha256d}

Estimates based on this calculation are shown in Table
\ref{tbl:supercop:sha256d}. What we can see that for lower lengths of data,
more of the candidates are faster than double \ac{SHA}-256. However, given the
practical situation that Tahoe-\ac{LAFS} is a file system, most files processed
<<<<<<< HEAD
will be larger than the file sizes estimated here. Not all hashing
operations in Tahoe-\ac{LAFS} are strictly dependant on the original file size,
which would mean that all candidates would have a chance of outperforming
double \ac{SHA}-256. However this estimate is worst case, which leads us to the
belief that at least for larger input sizes (over 1536) only the five fastest
candidates will have a change of outperforming double \ac{SHA}-256.

\section{Validity of \ac{SUPERCOP} results}
% Mention that some SUPERCOP candidates are missing UPDATE-functionality.

Although we believe the \ac{SUPERCOP} toolkit and results give good indication
of how fast the different candidate implementations are, we do have some
comments on it.

\paragraph{Implementations does not conform to \ac{NIST} specification} for
many of the candidates. By this we mean that there is no {\verb Update() }
function available for all implementations, and that \ac{SUPERCOP} only
measures speed of hashing full byte strings. This is also a hassle for a
programmer who wants to use the implementations in \ac{SUPERCOP}

\paragraph{Incorrect implementations} are present in \ac{SUPERCOP}. By this we
mean implementations that does not conform to the \ac{KAT}s supplied.

\paragraph{Results are only valid for one specific computer}. The results we
used from \ac{SUPERCOP} are only valid for our specific computer, although it
gives an indication of which speeds can be achieved on similar computers, i.e.
32-bit. However to get a complete picture of the performance of the different
candidates one must look at different computers and architectures. This picture
might be obtained from looking at the results from all computers measured by
\ac{SUPERCOP}.


%TODO: Vi har andre compiler argumenter - dette mÃ¥ diskuteres

\section{Exclusion of mutable file testing}
% Implications of only testing immutable files? (mutable files also
%   include directories)
% Adding a capability to support new hash functions in tahoe. (Our
%   current way breaks backwards compability)

Since our minor change in the Tahoe-\ac{LAFS} code broke internal checks, we
were not able to test mutable files, and hence not directories.

We argue that this has minor implications for our testing results. Both because
mutable files are not applicable for most use cases, since deleting an old
version and uploading a new file gives the same functionality, and because
immutable files uses less logic and therefore are more reliable and faster in
some cases. One should bear in mind that Tahoe-\ac{LAFS} is not a revision
control system, and mutable files are not intended for this purpose.

To be able to extend the Tahoe-LAFS with new functionality to fully support new
hash functions, one have to add a new capability \cite{t_zooko}. This ensures
backwards compatibility and can be an optional feature for users to employ.
However, we found that adding a new capability was out of scope for this
assignment.

% This chapter should contain (in listed and grouped order):
% -----------------------------------------------------------
% Describe inconsistencies in the numbers, and try to explain them.
% Time spent not hashing varies because: Variable use of CPU regs?
%
% Compare our results with general (SUPERCOP) results.
% Optimized candidates - which gain could be expected from more optimized
%   candidates?
% How much gain can Tahoe-LAFS get by switching to SHA-3?


%
% What if we had used another coding scheme? - does Cython lower the
%   candidates performance?
%
\section{The use of Cython}
The Python-bindings generated for Cython in C are not necessarily the most
optimized versions possible to write and they are ugly to read or change (from
a C perspective). However we consider them to be good enough, and they are
equal for all the \ac{SHA}-3 candidates which means they should give the same
performance penalty. The \ac{SHA}-256 version will of course not suffer from
the same penalty, however we believe the possible performance gain is small.
This is due to the fact that no intensive operations take place in our
Cython-code.

The alternative would be creating manual Python-bindings for all the candidates
which would require a lot more work on our side, especially given the lack of a
good enough and common \ac{API} for the implementations in \ac{SUPERCOP}.
Another fact important for this decision was that we did not know exactly which
implementation of each candidate we would end up using, and we ended up trying
several for most candidates.

\section{Thoughts on the measurements}



% More general stuff. What could have been done differently? Criticize
% ourselves.

%**************************************%
\chapter{Conclusion and Future Work}
%**************************************%

% This chapter should contain:
% -----------------------------------------------------------
% A somewhat short conclusion summing up what has been done, and results and
% discussion

We had hoped to contribute more to the Open Source project Tahoe-LAFS, when
starting on our assignment. It was early evident that implementing a new
capability was out of scope, since creating Python bindings for and trying out
new implementations was prioritized.

Perhaps the most important finding in this project, is that the SUPERCOP
benchmarking indeed drives the development of new and better implementations
forward, but since the SUPERCOP \ac{API} does not conform to the \ac{NIST}
\ac{API}, the developers leave important functionality out (i.e.
{\verb update() }), and hence make it difficult for people who wish to try out
and test the remaining \ac{SHA}-3 candidates.


% BibTeX bibliography lives in external file
\bibliographystyle{plainnat}
\bibliography{ref_sha3,ref_tahoe}

% Uncomment to enable appendices.
%\appendix
%\appendixpage
%\addappheadtotoc

% Use ordinary \chapters from here on..

\end{document}
